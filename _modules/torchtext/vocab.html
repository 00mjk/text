

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchtext.vocab &mdash; torchtext 0.4.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/pytorch_theme.css" type="text/css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css/family=Lato" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/pytorch-logo-dark.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.4.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">torchtext</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data.html">torchtext.data</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../data.html#dataset-batch-and-example">Dataset, Batch, and Example</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../data.html#dataset"><span class="hidden-section">Dataset</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../data.html#tabulardataset"><span class="hidden-section">TabularDataset</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../data.html#batch"><span class="hidden-section">Batch</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../data.html#example"><span class="hidden-section">Example</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../data.html#fields">Fields</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../data.html#rawfield"><span class="hidden-section">RawField</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../data.html#field"><span class="hidden-section">Field</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../data.html#reversiblefield"><span class="hidden-section">ReversibleField</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../data.html#subwordfield"><span class="hidden-section">SubwordField</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../data.html#nestedfield"><span class="hidden-section">NestedField</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../data.html#iterators">Iterators</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../data.html#iterator"><span class="hidden-section">Iterator</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../data.html#bucketiterator"><span class="hidden-section">BucketIterator</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../data.html#bpttiterator"><span class="hidden-section">BPTTIterator</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../data.html#pipeline">Pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../data.html#id1"><span class="hidden-section">Pipeline</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../data.html#functions">Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../data.html#id2"><span class="hidden-section">batch</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../data.html#pool"><span class="hidden-section">pool</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../data.html#get-tokenizer"><span class="hidden-section">get_tokenizer</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../data.html#interleave-keys"><span class="hidden-section">interleave_keys</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../datasets.html">torchtext.datasets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../datasets.html#sentiment-analysis">Sentiment Analysis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../datasets.html#sst">SST</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../datasets.html#imdb">IMDb</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../datasets.html#question-classification">Question Classification</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../datasets.html#trec">TREC</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../datasets.html#entailment">Entailment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../datasets.html#snli">SNLI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../datasets.html#multinli">MultiNLI</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../datasets.html#language-modeling">Language Modeling</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../datasets.html#wikitext-2">WikiText-2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../datasets.html#wikitext103">WikiText103</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../datasets.html#penntreebank">PennTreebank</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../datasets.html#machine-translation">Machine Translation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../datasets.html#multi30k">Multi30k</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../datasets.html#iwslt">IWSLT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../datasets.html#wmt14">WMT14</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../datasets.html#sequence-tagging">Sequence Tagging</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../datasets.html#udpos">UDPOS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../datasets.html#conll2000chunking">CoNLL2000Chunking</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../datasets.html#question-answering">Question Answering</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../datasets.html#babi20">BABI20</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../vocab.html">torchtext.vocab</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../vocab.html#vocab"><span class="hidden-section">Vocab</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../vocab.html#subwordvocab"><span class="hidden-section">SubwordVocab</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../vocab.html#vectors"><span class="hidden-section">Vectors</span></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../vocab.html#pretrained-word-embeddings">Pretrained Word Embeddings</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../vocab.html#glove"><span class="hidden-section">GloVe</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../vocab.html#fasttext"><span class="hidden-section">FastText</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../vocab.html#charngram"><span class="hidden-section">CharNGram</span></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../vocab.html#misc">Misc.</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../vocab.html#default-unk-index"><span class="hidden-section">_default_unk_index</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../vocab.html#pretrained-aliases"><span class="hidden-section">pretrained_aliases</span></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../utils.html">torchtext.utils</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../utils.html#reporthook"><span class="hidden-section">reporthook</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../utils.html#download-from-url"><span class="hidden-section">download_from_url</span></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../examples.html">Examples</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">torchtext</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>torchtext.vocab</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for torchtext.vocab</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">unicode_literals</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="k">import</span> <span class="n">partial</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">zipfile</span>
<span class="kn">import</span> <span class="nn">gzip</span>

<span class="kn">import</span> <span class="nn">six</span>
<span class="kn">from</span> <span class="nn">six.moves.urllib.request</span> <span class="k">import</span> <span class="n">urlretrieve</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="k">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">tarfile</span>

<span class="kn">from</span> <span class="nn">.utils</span> <span class="k">import</span> <span class="n">reporthook</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="Vocab"><a class="viewcode-back" href="../../vocab.html#torchtext.data.Vocab">[docs]</a><span class="k">class</span> <span class="nc">Vocab</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Defines a vocabulary object that will be used to numericalize a field.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        freqs: A collections.Counter object holding the frequencies of tokens</span>
<span class="sd">            in the data used to build the Vocab.</span>
<span class="sd">        stoi: A collections.defaultdict instance mapping token strings to</span>
<span class="sd">            numerical identifiers.</span>
<span class="sd">        itos: A list of token strings indexed by their numerical identifiers.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># TODO (@mttk): Populate classs with default values of special symbols</span>
    <span class="n">UNK</span> <span class="o">=</span> <span class="s1">&#39;&lt;unk&gt;&#39;</span>

<div class="viewcode-block" id="Vocab.__init__"><a class="viewcode-back" href="../../vocab.html#torchtext.data.Vocab.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">counter</span><span class="p">,</span> <span class="n">max_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">specials</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">],</span>
                 <span class="n">vectors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">unk_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vectors_cache</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">specials_first</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a Vocab object from a collections.Counter.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            counter: collections.Counter object holding the frequencies of</span>
<span class="sd">                each value found in the data.</span>
<span class="sd">            max_size: The maximum size of the vocabulary, or None for no</span>
<span class="sd">                maximum. Default: None.</span>
<span class="sd">            min_freq: The minimum frequency needed to include a token in the</span>
<span class="sd">                vocabulary. Values less than 1 will be set to 1. Default: 1.</span>
<span class="sd">            specials: The list of special tokens (e.g., padding or eos) that</span>
<span class="sd">                will be prepended to the vocabulary in addition to an &lt;unk&gt;</span>
<span class="sd">                token. Default: [&#39;&lt;pad&gt;&#39;]</span>
<span class="sd">            vectors: One of either the available pretrained vectors</span>
<span class="sd">                or custom pretrained vectors (see Vocab.load_vectors);</span>
<span class="sd">                or a list of aforementioned vectors</span>
<span class="sd">            unk_init (callback): by default, initialize out-of-vocabulary word vectors</span>
<span class="sd">                to zero vectors; can be any function that takes in a Tensor and</span>
<span class="sd">                returns a Tensor of the same size. Default: torch.Tensor.zero_</span>
<span class="sd">            vectors_cache: directory for cached vectors. Default: &#39;.vector_cache&#39;</span>
<span class="sd">            specials_first: Whether to add special tokens into the vocabulary at first.</span>
<span class="sd">                If it is False, they are added into the vocabulary at last.</span>
<span class="sd">                Default: True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">freqs</span> <span class="o">=</span> <span class="n">counter</span>
        <span class="n">counter</span> <span class="o">=</span> <span class="n">counter</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">min_freq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">min_freq</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">itos</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unk_index</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">specials_first</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">itos</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">specials</span><span class="p">)</span>
            <span class="c1"># only extend max size if specials are prepended</span>
            <span class="n">max_size</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">max_size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">max_size</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">specials</span><span class="p">)</span>

        <span class="c1"># frequencies of special tokens are not counted when building vocabulary</span>
        <span class="c1"># in frequency order</span>
        <span class="k">for</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">specials</span><span class="p">:</span>
            <span class="k">del</span> <span class="n">counter</span><span class="p">[</span><span class="n">tok</span><span class="p">]</span>

        <span class="c1"># sort by frequency, then alphabetically</span>
        <span class="n">words_and_frequencies</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">counter</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">tup</span><span class="p">:</span> <span class="n">tup</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">words_and_frequencies</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">tup</span><span class="p">:</span> <span class="n">tup</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">words_and_frequencies</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">freq</span> <span class="o">&lt;</span> <span class="n">min_freq</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">itos</span><span class="p">)</span> <span class="o">==</span> <span class="n">max_size</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">itos</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">Vocab</span><span class="o">.</span><span class="n">UNK</span> <span class="ow">in</span> <span class="n">specials</span><span class="p">:</span>  <span class="c1"># hard-coded for now</span>
            <span class="n">unk_index</span> <span class="o">=</span> <span class="n">specials</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">Vocab</span><span class="o">.</span><span class="n">UNK</span><span class="p">)</span>  <span class="c1"># position in list</span>
            <span class="c1"># account for ordering of specials, set variable</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">unk_index</span> <span class="o">=</span> <span class="n">unk_index</span> <span class="k">if</span> <span class="n">specials_first</span> <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">itos</span><span class="p">)</span> <span class="o">+</span> <span class="n">unk_index</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_default_unk_index</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">()</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">specials_first</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">itos</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">specials</span><span class="p">))</span>

        <span class="c1"># stoi is simply a reverse dict for itos</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">tok</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">tok</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">itos</span><span class="p">)})</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vectors</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">vectors</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load_vectors</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">unk_init</span><span class="o">=</span><span class="n">unk_init</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="n">vectors_cache</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">unk_init</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">vectors_cache</span> <span class="ow">is</span> <span class="kc">None</span></div>

    <span class="k">def</span> <span class="nf">_default_unk_index</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">unk_index</span>

    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># avoid picking defaultdict</span>
        <span class="n">attrs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>
        <span class="c1"># cast to regular dict</span>
        <span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;stoi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">attrs</span>

    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;unk_index&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">stoi</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">stoi</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_default_unk_index</span><span class="p">)</span>
        <span class="n">stoi</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s1">&#39;stoi&#39;</span><span class="p">])</span>
        <span class="n">state</span><span class="p">[</span><span class="s1">&#39;stoi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">stoi</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">freqs</span> <span class="o">!=</span> <span class="n">other</span><span class="o">.</span><span class="n">freqs</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span> <span class="o">!=</span> <span class="n">other</span><span class="o">.</span><span class="n">stoi</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">itos</span> <span class="o">!=</span> <span class="n">other</span><span class="o">.</span><span class="n">itos</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectors</span> <span class="o">!=</span> <span class="n">other</span><span class="o">.</span><span class="n">vectors</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">itos</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">extend</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">sort</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">words</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">itos</span><span class="p">)</span> <span class="k">if</span> <span class="n">sort</span> <span class="k">else</span> <span class="n">v</span><span class="o">.</span><span class="n">itos</span>
        <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">itos</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">itos</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

<div class="viewcode-block" id="Vocab.load_vectors"><a class="viewcode-back" href="../../vocab.html#torchtext.data.Vocab.load_vectors">[docs]</a>    <span class="k">def</span> <span class="nf">load_vectors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectors</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Arguments:</span>
<span class="sd">            vectors: one of or a list containing instantiations of the</span>
<span class="sd">                GloVe, CharNGram, or Vectors classes. Alternatively, one</span>
<span class="sd">                of or a list of available pretrained vectors:</span>
<span class="sd">                charngram.100d</span>
<span class="sd">                fasttext.en.300d</span>
<span class="sd">                fasttext.simple.300d</span>
<span class="sd">                glove.42B.300d</span>
<span class="sd">                glove.840B.300d</span>
<span class="sd">                glove.twitter.27B.25d</span>
<span class="sd">                glove.twitter.27B.50d</span>
<span class="sd">                glove.twitter.27B.100d</span>
<span class="sd">                glove.twitter.27B.200d</span>
<span class="sd">                glove.6B.50d</span>
<span class="sd">                glove.6B.100d</span>
<span class="sd">                glove.6B.200d</span>
<span class="sd">                glove.6B.300d</span>
<span class="sd">            Remaining keyword arguments: Passed to the constructor of Vectors classes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">vectors</span> <span class="o">=</span> <span class="p">[</span><span class="n">vectors</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">vector</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vectors</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">six</span><span class="o">.</span><span class="n">PY2</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vector</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">vector</span> <span class="o">=</span> <span class="n">six</span><span class="o">.</span><span class="n">text_type</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vector</span><span class="p">,</span> <span class="n">six</span><span class="o">.</span><span class="n">string_types</span><span class="p">):</span>
                <span class="c1"># Convert the string pretrained vector identifier</span>
                <span class="c1"># to a Vectors object</span>
                <span class="k">if</span> <span class="n">vector</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">pretrained_aliases</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;Got string input vector </span><span class="si">{}</span><span class="s2">, but allowed pretrained &quot;</span>
                        <span class="s2">&quot;vectors are </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                            <span class="n">vector</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">pretrained_aliases</span><span class="o">.</span><span class="n">keys</span><span class="p">())))</span>
                <span class="n">vectors</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">pretrained_aliases</span><span class="p">[</span><span class="n">vector</span><span class="p">](</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vector</span><span class="p">,</span> <span class="n">Vectors</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Got input vectors of type </span><span class="si">{}</span><span class="s2">, expected str or &quot;</span>
                    <span class="s2">&quot;Vectors object&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">vector</span><span class="p">)))</span>

        <span class="n">tot_dim</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">dim</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vectors</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vectors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="n">tot_dim</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">itos</span><span class="p">):</span>
            <span class="n">start_dim</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vectors</span><span class="p">:</span>
                <span class="n">end_dim</span> <span class="o">=</span> <span class="n">start_dim</span> <span class="o">+</span> <span class="n">v</span><span class="o">.</span><span class="n">dim</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">vectors</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">start_dim</span><span class="p">:</span><span class="n">end_dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="p">[</span><span class="n">token</span><span class="o">.</span><span class="n">strip</span><span class="p">()]</span>
                <span class="n">start_dim</span> <span class="o">=</span> <span class="n">end_dim</span>
            <span class="k">assert</span><span class="p">(</span><span class="n">start_dim</span> <span class="o">==</span> <span class="n">tot_dim</span><span class="p">)</span></div>

<div class="viewcode-block" id="Vocab.set_vectors"><a class="viewcode-back" href="../../vocab.html#torchtext.data.Vocab.set_vectors">[docs]</a>    <span class="k">def</span> <span class="nf">set_vectors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stoi</span><span class="p">,</span> <span class="n">vectors</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">unk_init</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">.</span><span class="n">zero_</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the vectors for the Vocab instance from a collection of Tensors.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            stoi: A dictionary of string to the index of the associated vector</span>
<span class="sd">                in the `vectors` input argument.</span>
<span class="sd">            vectors: An indexed iterable (or other structure supporting __getitem__) that</span>
<span class="sd">                given an input index, returns a FloatTensor representing the vector</span>
<span class="sd">                for the token associated with the index. For example,</span>
<span class="sd">                vector[stoi[&quot;string&quot;]] should return the vector for &quot;string&quot;.</span>
<span class="sd">            dim: The dimensionality of the vectors.</span>
<span class="sd">            unk_init (callback): by default, initialize out-of-vocabulary word vectors</span>
<span class="sd">                to zero vectors; can be any function that takes in a Tensor and</span>
<span class="sd">                returns a Tensor of the same size. Default: torch.Tensor.zero_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vectors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="n">dim</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">itos</span><span class="p">):</span>
            <span class="n">wv_index</span> <span class="o">=</span> <span class="n">stoi</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">wv_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">vectors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">vectors</span><span class="p">[</span><span class="n">wv_index</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">vectors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">unk_init</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vectors</span><span class="p">[</span><span class="n">i</span><span class="p">])</span></div></div>


<div class="viewcode-block" id="SubwordVocab"><a class="viewcode-back" href="../../vocab.html#torchtext.data.SubwordVocab">[docs]</a><span class="k">class</span> <span class="nc">SubwordVocab</span><span class="p">(</span><span class="n">Vocab</span><span class="p">):</span>

<div class="viewcode-block" id="SubwordVocab.__init__"><a class="viewcode-back" href="../../vocab.html#torchtext.data.SubwordVocab.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">counter</span><span class="p">,</span> <span class="n">max_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">specials</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">],</span>
                 <span class="n">vectors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">unk_init</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">.</span><span class="n">zero_</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a revtok subword vocabulary from a collections.Counter.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            counter: collections.Counter object holding the frequencies of</span>
<span class="sd">                each word found in the data.</span>
<span class="sd">            max_size: The maximum size of the subword vocabulary, or None for no</span>
<span class="sd">                maximum. Default: None.</span>
<span class="sd">            specials: The list of special tokens (e.g., padding or eos) that</span>
<span class="sd">                will be prepended to the vocabulary in addition to an &lt;unk&gt;</span>
<span class="sd">                token.</span>
<span class="sd">            vectors: One of either the available pretrained vectors</span>
<span class="sd">                or custom pretrained vectors (see Vocab.load_vectors);</span>
<span class="sd">                or a list of aforementioned vectors</span>
<span class="sd">            unk_init (callback): by default, initialize out-of-vocabulary word vectors</span>
<span class="sd">                to zero vectors; can be any function that takes in a Tensor and</span>
<span class="sd">                returns a Tensor of the same size. Default: torch.Tensor.zero_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">revtok</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Please install revtok.&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

        <span class="c1"># Hardcode unk_index as subword_vocab has no specials_first argument</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unk_index</span> <span class="o">=</span> <span class="p">(</span><span class="n">specials</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">SubwordVocab</span><span class="o">.</span><span class="n">UNK</span><span class="p">)</span>
                          <span class="k">if</span> <span class="n">SubwordVocab</span><span class="o">.</span><span class="n">UNK</span> <span class="ow">in</span> <span class="n">specials</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">unk_index</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_default_unk_index</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">tok</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">tok</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">specials</span><span class="p">)})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">itos</span> <span class="o">=</span> <span class="n">specials</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">segment</span> <span class="o">=</span> <span class="n">revtok</span><span class="o">.</span><span class="n">SubwordSegmenter</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span> <span class="n">max_size</span><span class="p">)</span>

        <span class="n">max_size</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">max_size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">max_size</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">itos</span><span class="p">)</span>

        <span class="c1"># sort by frequency/entropy, then alphabetically</span>
        <span class="n">toks</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">segment</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span>
                      <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">tup</span><span class="p">:</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tup</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="n">tup</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">tup</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

        <span class="k">for</span> <span class="n">tok</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">toks</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">itos</span><span class="p">)</span> <span class="o">==</span> <span class="n">max_size</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">itos</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tok</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="p">[</span><span class="n">tok</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">itos</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">vectors</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load_vectors</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">unk_init</span><span class="o">=</span><span class="n">unk_init</span><span class="p">)</span></div></div>


<span class="k">def</span> <span class="nf">_infer_shape</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="n">num_lines</span><span class="p">,</span> <span class="n">vector_dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">vector_dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">row</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
            <span class="n">vector</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
            <span class="c1"># Assuming word, [vector] format</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="c1"># The header present in some (w2v) formats contains two elements.</span>
                <span class="n">vector_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span>
                <span class="n">num_lines</span> <span class="o">+=</span> <span class="mi">1</span>  <span class="c1"># First element read</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">num_lines</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">f</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">num_lines</span><span class="p">,</span> <span class="n">vector_dim</span>


<div class="viewcode-block" id="Vectors"><a class="viewcode-back" href="../../vocab.html#torchtext.data.Vectors">[docs]</a><span class="k">class</span> <span class="nc">Vectors</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

<div class="viewcode-block" id="Vectors.__init__"><a class="viewcode-back" href="../../vocab.html#torchtext.data.Vectors.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">url</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">unk_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_vectors</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Arguments:</span>
<span class="sd">           name: name of the file that contains the vectors</span>
<span class="sd">           cache: directory for cached vectors</span>
<span class="sd">           url: url for download if vectors not found in cache</span>
<span class="sd">           unk_init (callback): by default, initialize out-of-vocabulary word vectors</span>
<span class="sd">               to zero vectors; can be any function that takes in a Tensor and</span>
<span class="sd">               returns a Tensor of the same size</span>
<span class="sd">           max_vectors (int): this can be used to limit the number of</span>
<span class="sd">               pre-trained vectors loaded.</span>
<span class="sd">               Most pre-trained vector sets are sorted</span>
<span class="sd">               in the descending order of word frequency.</span>
<span class="sd">               Thus, in situations where the entire set doesn&#39;t fit in memory,</span>
<span class="sd">               or is not needed for another reason, passing `max_vectors`</span>
<span class="sd">               can limit the size of the loaded set.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cache</span> <span class="o">=</span> <span class="s1">&#39;.vector_cache&#39;</span> <span class="k">if</span> <span class="n">cache</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">cache</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">itos</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vectors</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unk_init</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">.</span><span class="n">zero_</span> <span class="k">if</span> <span class="n">unk_init</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">unk_init</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">cache</span><span class="p">,</span> <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">max_vectors</span><span class="o">=</span><span class="n">max_vectors</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectors</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="p">[</span><span class="n">token</span><span class="p">]]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">unk_init</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">cache</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">cache</span><span class="p">,</span> <span class="n">url</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_vectors</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
            <span class="n">path</span> <span class="o">=</span> <span class="n">name</span>
            <span class="k">if</span> <span class="n">max_vectors</span><span class="p">:</span>
                <span class="n">file_suffix</span> <span class="o">=</span> <span class="s1">&#39;_</span><span class="si">{}</span><span class="s1">.pt&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">max_vectors</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">file_suffix</span> <span class="o">=</span> <span class="s1">&#39;.pt&#39;</span>
            <span class="n">path_pt</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cache</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">name</span><span class="p">))</span> <span class="o">+</span> <span class="n">file_suffix</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cache</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">max_vectors</span><span class="p">:</span>
                <span class="n">file_suffix</span> <span class="o">=</span> <span class="s1">&#39;_</span><span class="si">{}</span><span class="s1">.pt&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">max_vectors</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">file_suffix</span> <span class="o">=</span> <span class="s1">&#39;.pt&#39;</span>
            <span class="n">path_pt</span> <span class="o">=</span> <span class="n">path</span> <span class="o">+</span> <span class="n">file_suffix</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">path_pt</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="ow">and</span> <span class="n">url</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Downloading vectors from </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">url</span><span class="p">))</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">cache</span><span class="p">):</span>
                    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">cache</span><span class="p">)</span>
                <span class="n">dest</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cache</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">url</span><span class="p">))</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">dest</span><span class="p">):</span>
                    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">unit</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">unit_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">miniters</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="n">dest</span><span class="p">)</span> <span class="k">as</span> <span class="n">t</span><span class="p">:</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">dest</span><span class="p">,</span> <span class="n">reporthook</span><span class="o">=</span><span class="n">reporthook</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
                        <span class="k">except</span> <span class="ne">KeyboardInterrupt</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>  <span class="c1"># remove the partial zip file</span>
                            <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">dest</span><span class="p">)</span>
                            <span class="k">raise</span> <span class="n">e</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Extracting vectors into </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cache</span><span class="p">))</span>
                <span class="n">ext</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">dest</span><span class="p">)[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span>
                <span class="k">if</span> <span class="n">ext</span> <span class="o">==</span> <span class="s1">&#39;zip&#39;</span><span class="p">:</span>
                    <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">zf</span><span class="p">:</span>
                        <span class="n">zf</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="n">cache</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">ext</span> <span class="o">==</span> <span class="s1">&#39;gz&#39;</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">dest</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;.tar.gz&#39;</span><span class="p">):</span>
                        <span class="k">with</span> <span class="n">tarfile</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="s1">&#39;r:gz&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">tar</span><span class="p">:</span>
                            <span class="n">tar</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">cache</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;no vectors found at </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading vectors from </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
            <span class="n">ext</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">path</span><span class="p">)[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span>
            <span class="k">if</span> <span class="n">ext</span> <span class="o">==</span> <span class="s1">&#39;gz&#39;</span><span class="p">:</span>
                <span class="n">open_file</span> <span class="o">=</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">open_file</span> <span class="o">=</span> <span class="nb">open</span>

            <span class="n">vectors_loaded</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">with</span> <span class="n">open_file</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">num_lines</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="n">_infer_shape</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">max_vectors</span> <span class="ow">or</span> <span class="n">max_vectors</span> <span class="o">&gt;</span> <span class="n">num_lines</span><span class="p">:</span>
                    <span class="n">max_vectors</span> <span class="o">=</span> <span class="n">num_lines</span>

                <span class="n">itos</span><span class="p">,</span> <span class="n">vectors</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="p">[],</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">max_vectors</span><span class="p">,</span> <span class="n">dim</span><span class="p">)),</span> <span class="kc">None</span>

                <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">max_vectors</span><span class="p">):</span>
                    <span class="c1"># Explicitly splitting on &quot; &quot; is important, so we don&#39;t</span>
                    <span class="c1"># get rid of Unicode non-breaking spaces in the vectors.</span>
                    <span class="n">entries</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot; &quot;</span><span class="p">)</span>

                    <span class="n">word</span><span class="p">,</span> <span class="n">entries</span> <span class="o">=</span> <span class="n">entries</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">entries</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
                    <span class="k">if</span> <span class="n">dim</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">entries</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">entries</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">entries</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Skipping token </span><span class="si">{}</span><span class="s2"> with 1-dimensional &quot;</span>
                                       <span class="s2">&quot;vector </span><span class="si">{}</span><span class="s2">; likely a header&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">entries</span><span class="p">))</span>
                        <span class="k">continue</span>
                    <span class="k">elif</span> <span class="n">dim</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">entries</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                            <span class="s2">&quot;Vector for token </span><span class="si">{}</span><span class="s2"> has </span><span class="si">{}</span><span class="s2"> dimensions, but previously &quot;</span>
                            <span class="s2">&quot;read vectors have </span><span class="si">{}</span><span class="s2"> dimensions. All vectors must have &quot;</span>
                            <span class="s2">&quot;the same number of dimensions.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">entries</span><span class="p">),</span>
                                                                    <span class="n">dim</span><span class="p">))</span>

                    <span class="k">try</span><span class="p">:</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">six</span><span class="o">.</span><span class="n">binary_type</span><span class="p">):</span>
                            <span class="n">word</span> <span class="o">=</span> <span class="n">word</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
                    <span class="k">except</span> <span class="ne">UnicodeDecodeError</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Skipping non-UTF8 token </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">repr</span><span class="p">(</span><span class="n">word</span><span class="p">)))</span>
                        <span class="k">continue</span>

                    <span class="n">vectors</span><span class="p">[</span><span class="n">vectors_loaded</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">entries</span><span class="p">])</span>
                    <span class="n">vectors_loaded</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">itos</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

                    <span class="k">if</span> <span class="n">vectors_loaded</span> <span class="o">==</span> <span class="n">max_vectors</span><span class="p">:</span>
                        <span class="k">break</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">itos</span> <span class="o">=</span> <span class="n">itos</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span> <span class="o">=</span> <span class="p">{</span><span class="n">word</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">itos</span><span class="p">)}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vectors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Saving vectors to </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path_pt</span><span class="p">))</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">cache</span><span class="p">):</span>
                <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">cache</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">itos</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectors</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">),</span> <span class="n">path_pt</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Loading vectors from </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path_pt</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">itos</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectors</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path_pt</span><span class="p">)</span></div>


<div class="viewcode-block" id="GloVe"><a class="viewcode-back" href="../../vocab.html#torchtext.data.GloVe">[docs]</a><span class="k">class</span> <span class="nc">GloVe</span><span class="p">(</span><span class="n">Vectors</span><span class="p">):</span>
    <span class="n">url</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;42B&#39;</span><span class="p">:</span> <span class="s1">&#39;http://nlp.stanford.edu/data/glove.42B.300d.zip&#39;</span><span class="p">,</span>
        <span class="s1">&#39;840B&#39;</span><span class="p">:</span> <span class="s1">&#39;http://nlp.stanford.edu/data/glove.840B.300d.zip&#39;</span><span class="p">,</span>
        <span class="s1">&#39;twitter.27B&#39;</span><span class="p">:</span> <span class="s1">&#39;http://nlp.stanford.edu/data/glove.twitter.27B.zip&#39;</span><span class="p">,</span>
        <span class="s1">&#39;6B&#39;</span><span class="p">:</span> <span class="s1">&#39;http://nlp.stanford.edu/data/glove.6B.zip&#39;</span><span class="p">,</span>
    <span class="p">}</span>

<div class="viewcode-block" id="GloVe.__init__"><a class="viewcode-back" href="../../vocab.html#torchtext.data.GloVe.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;840B&#39;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">url</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;glove.</span><span class="si">{}</span><span class="s1">.</span><span class="si">{}</span><span class="s1">d.txt&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GloVe</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="FastText"><a class="viewcode-back" href="../../vocab.html#torchtext.data.FastText">[docs]</a><span class="k">class</span> <span class="nc">FastText</span><span class="p">(</span><span class="n">Vectors</span><span class="p">):</span>

    <span class="n">url_base</span> <span class="o">=</span> <span class="s1">&#39;https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.</span><span class="si">{}</span><span class="s1">.vec&#39;</span>

<div class="viewcode-block" id="FastText.__init__"><a class="viewcode-back" href="../../vocab.html#torchtext.data.FastText.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">language</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">url_base</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">language</span><span class="p">)</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FastText</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="CharNGram"><a class="viewcode-back" href="../../vocab.html#torchtext.data.CharNGram">[docs]</a><span class="k">class</span> <span class="nc">CharNGram</span><span class="p">(</span><span class="n">Vectors</span><span class="p">):</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;charNgram.txt&#39;</span>
    <span class="n">url</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;http://www.logos.t.u-tokyo.ac.jp/~hassy/publications/arxiv2016jmt/&#39;</span>
           <span class="s1">&#39;jmt_pre-trained_embeddings.tar.gz&#39;</span><span class="p">)</span>

<div class="viewcode-block" id="CharNGram.__init__"><a class="viewcode-back" href="../../vocab.html#torchtext.data.CharNGram.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CharNGram</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">url</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">url</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
        <span class="n">vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">token</span> <span class="o">==</span> <span class="s2">&quot;&lt;unk&gt;&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">unk_init</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span>
        <span class="c1"># These literals need to be coerced to unicode for Python 2 compatibility</span>
        <span class="c1"># when we try to join them with read ngrams from the files.</span>
        <span class="n">chars</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;#BEGIN#&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;#END#&#39;</span><span class="p">]</span>
        <span class="n">num_vectors</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]:</span>
            <span class="n">end</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span> <span class="o">-</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">grams</span> <span class="o">=</span> <span class="p">[</span><span class="n">chars</span><span class="p">[</span><span class="n">i</span><span class="p">:(</span><span class="n">i</span> <span class="o">+</span> <span class="n">n</span><span class="p">)]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">end</span><span class="p">)]</span>
            <span class="k">for</span> <span class="n">gram</span> <span class="ow">in</span> <span class="n">grams</span><span class="p">:</span>
                <span class="n">gram_key</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">{}</span><span class="s1">gram-</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">gram</span><span class="p">))</span>
                <span class="k">if</span> <span class="n">gram_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="p">:</span>
                    <span class="n">vector</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectors</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="p">[</span><span class="n">gram_key</span><span class="p">]]</span>
                    <span class="n">num_vectors</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">num_vectors</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">vector</span> <span class="o">/=</span> <span class="n">num_vectors</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unk_init</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">vector</span></div>


<span class="n">pretrained_aliases</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;charngram.100d&quot;</span><span class="p">:</span> <span class="n">partial</span><span class="p">(</span><span class="n">CharNGram</span><span class="p">),</span>
    <span class="s2">&quot;fasttext.en.300d&quot;</span><span class="p">:</span> <span class="n">partial</span><span class="p">(</span><span class="n">FastText</span><span class="p">,</span> <span class="n">language</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">),</span>
    <span class="s2">&quot;fasttext.simple.300d&quot;</span><span class="p">:</span> <span class="n">partial</span><span class="p">(</span><span class="n">FastText</span><span class="p">,</span> <span class="n">language</span><span class="o">=</span><span class="s2">&quot;simple&quot;</span><span class="p">),</span>
    <span class="s2">&quot;glove.42B.300d&quot;</span><span class="p">:</span> <span class="n">partial</span><span class="p">(</span><span class="n">GloVe</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;42B&quot;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="s2">&quot;300&quot;</span><span class="p">),</span>
    <span class="s2">&quot;glove.840B.300d&quot;</span><span class="p">:</span> <span class="n">partial</span><span class="p">(</span><span class="n">GloVe</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;840B&quot;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="s2">&quot;300&quot;</span><span class="p">),</span>
    <span class="s2">&quot;glove.twitter.27B.25d&quot;</span><span class="p">:</span> <span class="n">partial</span><span class="p">(</span><span class="n">GloVe</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;twitter.27B&quot;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="s2">&quot;25&quot;</span><span class="p">),</span>
    <span class="s2">&quot;glove.twitter.27B.50d&quot;</span><span class="p">:</span> <span class="n">partial</span><span class="p">(</span><span class="n">GloVe</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;twitter.27B&quot;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="s2">&quot;50&quot;</span><span class="p">),</span>
    <span class="s2">&quot;glove.twitter.27B.100d&quot;</span><span class="p">:</span> <span class="n">partial</span><span class="p">(</span><span class="n">GloVe</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;twitter.27B&quot;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="s2">&quot;100&quot;</span><span class="p">),</span>
    <span class="s2">&quot;glove.twitter.27B.200d&quot;</span><span class="p">:</span> <span class="n">partial</span><span class="p">(</span><span class="n">GloVe</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;twitter.27B&quot;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="s2">&quot;200&quot;</span><span class="p">),</span>
    <span class="s2">&quot;glove.6B.50d&quot;</span><span class="p">:</span> <span class="n">partial</span><span class="p">(</span><span class="n">GloVe</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;6B&quot;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="s2">&quot;50&quot;</span><span class="p">),</span>
    <span class="s2">&quot;glove.6B.100d&quot;</span><span class="p">:</span> <span class="n">partial</span><span class="p">(</span><span class="n">GloVe</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;6B&quot;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="s2">&quot;100&quot;</span><span class="p">),</span>
    <span class="s2">&quot;glove.6B.200d&quot;</span><span class="p">:</span> <span class="n">partial</span><span class="p">(</span><span class="n">GloVe</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;6B&quot;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="s2">&quot;200&quot;</span><span class="p">),</span>
    <span class="s2">&quot;glove.6B.300d&quot;</span><span class="p">:</span> <span class="n">partial</span><span class="p">(</span><span class="n">GloVe</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;6B&quot;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="s2">&quot;300&quot;</span><span class="p">)</span>
<span class="p">}</span>
<span class="sd">&quot;&quot;&quot;Mapping from string name to factory function&quot;&quot;&quot;</span>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Torch Contributors

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>